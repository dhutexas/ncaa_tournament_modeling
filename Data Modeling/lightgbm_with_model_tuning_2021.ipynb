{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Game Outcomes with LGBM\n",
    "#### Predicting the NCAA Mens Basketball Tournament, Game-by-Game\n",
    "\n",
    "Light GBM is a tree-based gradient-boosting algorithm. Instead of growing trees horizontally, LGBM grows trees vertically (leaf-wise instead of level-wise). This change in methodology can reduce loss better than a level-wise algorithm, but is subject to problems with overfitting.\n",
    "\n",
    "The following code utilizes the LGBM algorithm, with hyperparameter tuning through grid search, to predict the outcomes of the Mens NCAA College Basketball Tournament, as part of the Kaggle challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 22.90 MB\n",
      "Memory usage after optimization is: 5.63 MB\n",
      "Decreased by 75.4%\n",
      "Memory usage of dataframe is 0.42 MB\n",
      "Memory usage after optimization is: 0.10 MB\n",
      "Decreased by 75.3%\n"
     ]
    }
   ],
   "source": [
    "# for training models\n",
    "#tourney_result = import_data('Data/trainfull.csv')\n",
    "#test_df = import_data('Data/testfull.csv')\n",
    "\n",
    "# for submission models\n",
    "tourney_result = import_data('Data/train_data_through_2020.csv')\n",
    "test_df = import_data('Data/test_data_2021_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>result</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LScore</th>\n",
       "      <th>T1Rank</th>\n",
       "      <th>T1Conf</th>\n",
       "      <th>T1adj_EM</th>\n",
       "      <th>T1adj_OffEff</th>\n",
       "      <th>...</th>\n",
       "      <th>T2Luck</th>\n",
       "      <th>T2sos_adj_em</th>\n",
       "      <th>T2ncsos_adj_em</th>\n",
       "      <th>OffDiffadj</th>\n",
       "      <th>DefDiffadj</th>\n",
       "      <th>EMDiffadj</th>\n",
       "      <th>t1diff</th>\n",
       "      <th>t2diff</th>\n",
       "      <th>sos_diff</th>\n",
       "      <th>ncsos_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>1112</td>\n",
       "      <td>1268</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>67</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.546875</td>\n",
       "      <td>119.3125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>9.882812</td>\n",
       "      <td>1.620117</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>-8.710938</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>29.296875</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>15.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1196</td>\n",
       "      <td>1396</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>64</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.718750</td>\n",
       "      <td>115.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037994</td>\n",
       "      <td>8.039062</td>\n",
       "      <td>14.742188</td>\n",
       "      <td>1.099609</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>11.148438</td>\n",
       "      <td>24.703125</td>\n",
       "      <td>13.601562</td>\n",
       "      <td>1.070312</td>\n",
       "      <td>-15.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>1112</td>\n",
       "      <td>1196</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.546875</td>\n",
       "      <td>119.3125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072998</td>\n",
       "      <td>9.109375</td>\n",
       "      <td>-0.560059</td>\n",
       "      <td>4.199219</td>\n",
       "      <td>8.398438</td>\n",
       "      <td>-4.179688</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>24.703125</td>\n",
       "      <td>5.109375</td>\n",
       "      <td>18.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>1268</td>\n",
       "      <td>1396</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>119.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037994</td>\n",
       "      <td>8.039062</td>\n",
       "      <td>14.742188</td>\n",
       "      <td>5.199219</td>\n",
       "      <td>-10.500000</td>\n",
       "      <td>15.679688</td>\n",
       "      <td>29.296875</td>\n",
       "      <td>13.601562</td>\n",
       "      <td>1.839844</td>\n",
       "      <td>-13.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>1116</td>\n",
       "      <td>1263</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.562500</td>\n",
       "      <td>108.8125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>-10.390625</td>\n",
       "      <td>-7.199219</td>\n",
       "      <td>14.601562</td>\n",
       "      <td>-11.898438</td>\n",
       "      <td>26.468750</td>\n",
       "      <td>12.601562</td>\n",
       "      <td>-13.898438</td>\n",
       "      <td>21.640625</td>\n",
       "      <td>12.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Team1  Team2  result  WScore  LScore  T1Rank  T1Conf   T1adj_EM  \\\n",
       "0    2002   1112   1268       1      71      67    13.0     1.0  20.546875   \n",
       "1    2002   1196   1396       1      72      64     7.0     1.0  24.718750   \n",
       "2    2002   1112   1196       1      75      71    13.0     1.0  20.546875   \n",
       "3    2002   1268   1396       1      82      74     3.0     1.0  29.250000   \n",
       "4    2002   1116   1263       1      64      47    57.0     1.0  12.562500   \n",
       "\n",
       "   T1adj_OffEff  ...    T2Luck  T2sos_adj_em  T2ncsos_adj_em  OffDiffadj  \\\n",
       "0      119.3125  ...  0.024994      9.882812        1.620117    0.099976   \n",
       "1      115.1250  ... -0.037994      8.039062       14.742188    1.099609   \n",
       "2      119.3125  ... -0.072998      9.109375       -0.560059    4.199219   \n",
       "3      119.1875  ... -0.037994      8.039062       14.742188    5.199219   \n",
       "4      108.8125  ...  0.007000    -10.390625       -7.199219   14.601562   \n",
       "\n",
       "   DefDiffadj  EMDiffadj     t1diff     t2diff   sos_diff  ncsos_diff  \n",
       "0    8.898438  -8.710938  20.500000  29.296875   4.339844   15.937500  \n",
       "1  -10.000000  11.148438  24.703125  13.601562   1.070312  -15.296875  \n",
       "2    8.398438  -4.179688  20.500000  24.703125   5.109375   18.125000  \n",
       "3  -10.500000  15.679688  29.296875  13.601562   1.839844  -13.117188  \n",
       "4  -11.898438  26.468750  12.601562 -13.898438  21.640625   12.031250  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourney_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selects all available columns, so must subset desired columns at this point\n",
    "tourney_result = tourney_result[['result','OffDiffadj','DefDiffadj','T1Luck','T2Luck','sos_diff','ncsos_diff']]\n",
    "test_df = test_df[['OffDiffadj','DefDiffadj','T1Luck','T2Luck','sos_diff','ncsos_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>OffDiffadj</th>\n",
       "      <th>DefDiffadj</th>\n",
       "      <th>T1Luck</th>\n",
       "      <th>T2Luck</th>\n",
       "      <th>sos_diff</th>\n",
       "      <th>ncsos_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>8.898438</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>15.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.099609</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-0.072998</td>\n",
       "      <td>-0.037994</td>\n",
       "      <td>1.070312</td>\n",
       "      <td>-15.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.199219</td>\n",
       "      <td>8.398438</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>-0.072998</td>\n",
       "      <td>5.109375</td>\n",
       "      <td>18.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5.199219</td>\n",
       "      <td>-10.500000</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>-0.037994</td>\n",
       "      <td>1.839844</td>\n",
       "      <td>-13.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.601562</td>\n",
       "      <td>-11.898438</td>\n",
       "      <td>-0.062012</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>21.640625</td>\n",
       "      <td>12.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   result  OffDiffadj  DefDiffadj    T1Luck    T2Luck   sos_diff  ncsos_diff\n",
       "0       1    0.099976    8.898438  0.078979  0.024994   4.339844   15.937500\n",
       "1       1    1.099609  -10.000000 -0.072998 -0.037994   1.070312  -15.296875\n",
       "2       1    4.199219    8.398438  0.078979 -0.072998   5.109375   18.125000\n",
       "3       1    5.199219  -10.500000  0.024994 -0.037994   1.839844  -13.117188\n",
       "4       1   14.601562  -11.898438 -0.062012  0.007000  21.640625   12.031250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourney_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OffDiffadj</th>\n",
       "      <th>DefDiffadj</th>\n",
       "      <th>T1Luck</th>\n",
       "      <th>T2Luck</th>\n",
       "      <th>sos_diff</th>\n",
       "      <th>ncsos_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.300781</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.050995</td>\n",
       "      <td>-14.226562</td>\n",
       "      <td>-6.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.500000</td>\n",
       "      <td>6.101562</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>-20.906250</td>\n",
       "      <td>-7.378906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.898438</td>\n",
       "      <td>3.199219</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>-0.029007</td>\n",
       "      <td>-19.156250</td>\n",
       "      <td>-0.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12.203125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>-6.691406</td>\n",
       "      <td>-8.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.900391</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.035004</td>\n",
       "      <td>-7.011719</td>\n",
       "      <td>-0.810059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OffDiffadj  DefDiffadj    T1Luck    T2Luck   sos_diff  ncsos_diff\n",
       "0   -6.300781    3.800781  0.122986  0.050995 -14.226562   -6.300781\n",
       "1  -17.500000    6.101562  0.122986  0.008003 -20.906250   -7.378906\n",
       "2  -11.898438    3.199219  0.122986 -0.029007 -19.156250   -0.709961\n",
       "3  -12.203125    0.500000  0.122986  0.024994  -6.691406   -8.531250\n",
       "4    1.900391    0.600098  0.122986  0.035004  -7.011719   -0.810059"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tourney_result.drop('result', axis=1)\n",
    "y = tourney_result.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=23, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare learning rate shrinkage\n",
    "def learning_rate_010_decay_power_099(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.99, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def learning_rate_010_decay_power_0995(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def learning_rate_005_decay_power_099(current_iter):\n",
    "    base_learning_rate = 0.05\n",
    "    lr = base_learning_rate  * np.power(.99, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fit parameters, use early stopping to avoid overtraining and specification of # of trees\n",
    "fit_params={\"early_stopping_rounds\":100, \n",
    "            \"eval_metric\" : 'auc', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyperparameter search\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "param_test ={'num_leaves': sp_randint(3, 500), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid - from bayesian \n",
    "# https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a\n",
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(30, 150)),\n",
    "    'learning_rate': list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 1000)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_HP_points_to_test = 100\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=23, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    refit=True,\n",
    "    random_state=23,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837538\n",
      "[200]\tvalid's auc: 0.837668\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid's auc: 0.837691\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837681\n",
      "[200]\tvalid's auc: 0.837892\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid's auc: 0.837894\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837546\n",
      "[200]\tvalid's auc: 0.83773\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid's auc: 0.83773\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837513\n",
      "[200]\tvalid's auc: 0.837676\n",
      "[300]\tvalid's auc: 0.837675\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid's auc: 0.837679\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837276\n",
      "[200]\tvalid's auc: 0.837471\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid's auc: 0.837478\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832612\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid's auc: 0.835821\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833257\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid's auc: 0.836127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.83322\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.836054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833765\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.836133\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833508\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid's auc: 0.836141\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836445\n",
      "[200]\tvalid's auc: 0.837985\n",
      "[300]\tvalid's auc: 0.838207\n",
      "[400]\tvalid's auc: 0.838318\n",
      "[500]\tvalid's auc: 0.838353\n",
      "[600]\tvalid's auc: 0.838372\n",
      "[700]\tvalid's auc: 0.838357\n",
      "Early stopping, best iteration is:\n",
      "[601]\tvalid's auc: 0.838372\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.83653\n",
      "[200]\tvalid's auc: 0.83821\n",
      "[300]\tvalid's auc: 0.838421\n",
      "[400]\tvalid's auc: 0.838514\n",
      "[500]\tvalid's auc: 0.838522\n",
      "Early stopping, best iteration is:\n",
      "[439]\tvalid's auc: 0.838527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836496\n",
      "[200]\tvalid's auc: 0.838126\n",
      "[300]\tvalid's auc: 0.838421\n",
      "[400]\tvalid's auc: 0.838502\n",
      "[500]\tvalid's auc: 0.838548\n",
      "[600]\tvalid's auc: 0.838557\n",
      "[700]\tvalid's auc: 0.838566\n",
      "[800]\tvalid's auc: 0.838565\n",
      "Early stopping, best iteration is:\n",
      "[733]\tvalid's auc: 0.838568\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836477\n",
      "[200]\tvalid's auc: 0.838194\n",
      "[300]\tvalid's auc: 0.838454\n",
      "[400]\tvalid's auc: 0.838528\n",
      "[500]\tvalid's auc: 0.838534\n",
      "Early stopping, best iteration is:\n",
      "[475]\tvalid's auc: 0.838546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836394\n",
      "[200]\tvalid's auc: 0.838049\n",
      "[300]\tvalid's auc: 0.838299\n",
      "[400]\tvalid's auc: 0.838401\n",
      "[500]\tvalid's auc: 0.838433\n",
      "[600]\tvalid's auc: 0.838449\n",
      "[700]\tvalid's auc: 0.838447\n",
      "Early stopping, best iteration is:\n",
      "[633]\tvalid's auc: 0.838457\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834726\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid's auc: 0.836758\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.83537\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.83707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834738\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid's auc: 0.836803\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835295\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid's auc: 0.837229\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835138\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid's auc: 0.837127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837455\n",
      "[200]\tvalid's auc: 0.837712\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid's auc: 0.837719\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837673\n",
      "[200]\tvalid's auc: 0.837903\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid's auc: 0.837914\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.8376\n",
      "[200]\tvalid's auc: 0.837868\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid's auc: 0.837879\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837744\n",
      "[200]\tvalid's auc: 0.838073\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid's auc: 0.838073\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837473\n",
      "[200]\tvalid's auc: 0.837708\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid's auc: 0.837709\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834929\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.836675\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835669\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid's auc: 0.836903\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835544\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid's auc: 0.836893\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835362\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid's auc: 0.83664\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835615\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid's auc: 0.836911\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.83493\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid's auc: 0.836633\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835411\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid's auc: 0.837045\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835409\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid's auc: 0.837017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835522\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid's auc: 0.836962\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835403\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid's auc: 0.836825\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837488\n",
      "[200]\tvalid's auc: 0.837617\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid's auc: 0.837646\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.83754\n",
      "[200]\tvalid's auc: 0.837799\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid's auc: 0.837814\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837303\n",
      "[200]\tvalid's auc: 0.83749\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid's auc: 0.837499\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837612\n",
      "[200]\tvalid's auc: 0.837923\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid's auc: 0.837933\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837122\n",
      "[200]\tvalid's auc: 0.837395\n",
      "[300]\tvalid's auc: 0.837402\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid's auc: 0.837409\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836748\n",
      "[200]\tvalid's auc: 0.836864\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid's auc: 0.836869\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.83691\n",
      "[200]\tvalid's auc: 0.837033\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid's auc: 0.837036\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836576\n",
      "[200]\tvalid's auc: 0.836768\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid's auc: 0.836776\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836957\n",
      "[200]\tvalid's auc: 0.837114\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid's auc: 0.837121\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836413\n",
      "[200]\tvalid's auc: 0.836524\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid's auc: 0.836524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836264\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid's auc: 0.837193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836018\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid's auc: 0.837078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836368\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid's auc: 0.837188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836517\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid's auc: 0.837397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836279\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid's auc: 0.837123\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834316\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid's auc: 0.836341\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834554\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid's auc: 0.836837\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834164\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid's auc: 0.836602\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.8351\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid's auc: 0.836931\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834332\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid's auc: 0.836743\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838601\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid's auc: 0.838623\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.839052\n",
      "[200]\tvalid's auc: 0.838955\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid's auc: 0.839094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838662\n",
      "[200]\tvalid's auc: 0.838539\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid's auc: 0.838732\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.839059\n",
      "[200]\tvalid's auc: 0.838973\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid's auc: 0.839181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838708\n",
      "[200]\tvalid's auc: 0.838543\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid's auc: 0.838788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832704\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.83651\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833581\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid's auc: 0.837077\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833206\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid's auc: 0.836616\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833994\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid's auc: 0.837138\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833288\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid's auc: 0.836878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835801\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid's auc: 0.836837\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836462\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid's auc: 0.837391\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835972\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid's auc: 0.836978\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836356\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid's auc: 0.837203\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836437\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid's auc: 0.837289\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838053\n",
      "[200]\tvalid's auc: 0.837578\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid's auc: 0.838061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838711\n",
      "[200]\tvalid's auc: 0.838364\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid's auc: 0.838742\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838586\n",
      "[200]\tvalid's auc: 0.838139\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid's auc: 0.838622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838558\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid's auc: 0.838601\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.838327\n",
      "[200]\tvalid's auc: 0.837889\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid's auc: 0.838343\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.825902\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid's auc: 0.835203\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.826051\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid's auc: 0.835164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.825938\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid's auc: 0.834782\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.826804\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid's auc: 0.83587\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.826862\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid's auc: 0.836035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835286\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid's auc: 0.836843\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835653\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.837007\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836056\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.837121\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836316\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.837288\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835952\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid's auc: 0.837083\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.834861\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid's auc: 0.836224\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835542\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid's auc: 0.836706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835391\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid's auc: 0.836829\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835776\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid's auc: 0.83677\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835641\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.836787\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836908\n",
      "[200]\tvalid's auc: 0.837285\n",
      "[300]\tvalid's auc: 0.837425\n",
      "[400]\tvalid's auc: 0.837437\n",
      "[500]\tvalid's auc: 0.837451\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid's auc: 0.837472\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837334\n",
      "[200]\tvalid's auc: 0.837756\n",
      "[300]\tvalid's auc: 0.837764\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid's auc: 0.837783\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837009\n",
      "[200]\tvalid's auc: 0.837396\n",
      "[300]\tvalid's auc: 0.837512\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's auc: 0.837519\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837555\n",
      "[200]\tvalid's auc: 0.837929\n",
      "[300]\tvalid's auc: 0.837988\n",
      "[400]\tvalid's auc: 0.837971\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid's auc: 0.838021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837015\n",
      "[200]\tvalid's auc: 0.837397\n",
      "[300]\tvalid's auc: 0.837523\n",
      "[400]\tvalid's auc: 0.837521\n",
      "Early stopping, best iteration is:\n",
      "[373]\tvalid's auc: 0.837549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835422\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid's auc: 0.836636\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835642\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid's auc: 0.837063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835475\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.836624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835611\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid's auc: 0.836687\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.835911\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's auc: 0.836991\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832357\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.836871\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832511\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.836854\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832303\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid's auc: 0.836685\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833093\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid's auc: 0.837052\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833044\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.836822\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.836873\n",
      "[200]\tvalid's auc: 0.836959\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid's auc: 0.83698\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837259\n",
      "[200]\tvalid's auc: 0.837455\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid's auc: 0.837464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.83729\n",
      "[200]\tvalid's auc: 0.837405\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid's auc: 0.837405\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837087\n",
      "[200]\tvalid's auc: 0.837283\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid's auc: 0.837284\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.837119\n",
      "[200]\tvalid's auc: 0.83718\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid's auc: 0.837196\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832384\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.836584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832914\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid's auc: 0.836735\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.832963\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.836711\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833448\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid's auc: 0.836849\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833203\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.837028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833738\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid's auc: 0.836518\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833867\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.837122\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's auc: 0.833844\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.836809\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    }
   ],
   "source": [
    "# find optimal hyperparameters\n",
    "gs.fit(X_train, y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input best scores from search as new opt_parameters\n",
    "opt_parameters = {'colsample_bytree': 0.5814922697483688, \n",
    "                  'min_child_samples': 293, \n",
    "                  'min_child_weight': 0.1, \n",
    "                  'num_leaves': 5, \n",
    "                  'reg_alpha': 10, \n",
    "                  'reg_lambda': 10, \n",
    "                  'subsample': 0.8358356155097291}\n",
    "\n",
    "clf_sw = lgb.LGBMClassifier(**clf.get_params())\n",
    "\n",
    "#set optimal parameters\n",
    "clf_sw.set_params(**opt_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "gs_sample_weight = GridSearchCV(estimator=clf_sw, \n",
    "                                param_grid={'scale_pos_weight':[1,2,6,12]},\n",
    "                                scoring='roc_auc',\n",
    "                                cv=5,\n",
    "                                refit=True,\n",
    "                                verbose=True)\n",
    "\n",
    "gs_sample_weight.fit(X_train, y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs_sample_weight.best_score_, gs_sample_weight.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Fit with Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure from the HP optimisation - shortcut from doing above lines of code\n",
    "#clf_final = lgb.LGBMClassifier(**gs.best_estimator_.get_params())\n",
    "\n",
    "#Configure locally from hardcoded values\n",
    "clf_final = lgb.LGBMClassifier(**clf.get_params())\n",
    "\n",
    "#set optimal parameters\n",
    "clf_final.set_params(**opt_parameters)\n",
    "\n",
    "#Train the final model with learning rate decay\n",
    "clf_final.fit(X_train, y_train, **fit_params, \n",
    "              callbacks=[lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_0995)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(clf_final, \n",
    "                    height=0.5, max_num_features=20, ignore_zero = False, \n",
    "                    figsize = (12,6), importance_type ='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = clf_final.predict_proba(test_df)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('Data/submission_stage_two_2021.csv')\n",
    "submission = pd.DataFrame({\n",
    "    'ID': submission_df['ID'],\n",
    "    'Pred':     [ row[1] for row in probabilities]\n",
    "})\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick glance at the predictions across the entire range of matchups\n",
    "submission['Pred'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Data/submission_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
